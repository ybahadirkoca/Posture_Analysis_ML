{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715ffb2c-93c5-489d-858a-9b5e431ef1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LR Tuning & Evaluation for: Cervical Lordosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'penalty': 'l1', 'C': 1, 'solver': 'liblinear', 'class_weight': 'balanced', 'max_iter': 2000} | Mean CV (balanced_accuracy): 0.915\n",
      "\n",
      "=== LR Tuning & Evaluation for: Kyphosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'penalty': 'l2', 'C': 1, 'solver': 'liblinear', 'class_weight': 'balanced', 'max_iter': 2000} | Mean CV (balanced_accuracy): 0.792\n",
      "\n",
      "=== LR Tuning & Evaluation for: Lumbar Lordosis Risk ===\n",
      "Best params (Stratified 4-Fold): {'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'class_weight': 'balanced', 'max_iter': 2000} | Mean CV (balanced_accuracy): 0.533\n",
      "\n",
      "=== LR Tuning & Evaluation for: Scoliosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'penalty': 'l2', 'C': 10, 'solver': 'liblinear', 'class_weight': 'balanced', 'max_iter': 2000} | Mean CV (balanced_accuracy): 0.592\n",
      "\n",
      "=== Logistic Regression – Master Table (adaptive 5/10-Fold [+LOSO if enabled]) ===\n",
      "                   Target              Scheme  Accuracy  95% CI Low  \\\n",
      "0  Cervical Lordosis Risk   Stratified 5-Fold  0.866667    0.703187   \n",
      "1  Cervical Lordosis Risk   Stratified 6-Fold  0.866667    0.703187   \n",
      "2           Kyphosis Risk   Stratified 5-Fold  0.800000    0.626943   \n",
      "3           Kyphosis Risk  Stratified 10-Fold  0.766667    0.590717   \n",
      "4    Lumbar Lordosis Risk   Stratified 4-Fold  0.733333    0.555520   \n",
      "5    Lumbar Lordosis Risk   Stratified 4-Fold  0.733333    0.555520   \n",
      "6          Scoliosis Risk   Stratified 5-Fold  0.600000    0.423204   \n",
      "7          Scoliosis Risk  Stratified 10-Fold  0.566667    0.391973   \n",
      "\n",
      "   95% CI High  Weighted Precision  Weighted Recall  Weighted F1  Support  TN  \\\n",
      "0     0.946903            0.920000         0.866667     0.877273       30  20   \n",
      "1     0.946903            0.888636         0.866667     0.873292       30  21   \n",
      "2     0.904949            0.800000         0.800000     0.800000       30  11   \n",
      "3     0.882076            0.766817         0.766667     0.765881       30  10   \n",
      "4     0.858173            0.780556         0.733333     0.754667       30  21   \n",
      "5     0.858173            0.780556         0.733333     0.754667       30  21   \n",
      "6     0.754094            0.600000         0.600000     0.600000       30  11   \n",
      "7     0.726225            0.562963         0.566667     0.564190       30  11   \n",
      "\n",
      "   FP  FN  TP  \n",
      "0   4   0   6  \n",
      "1   3   1   5  \n",
      "2   3   3  13  \n",
      "3   4   3  13  \n",
      "4   5   3   1  \n",
      "5   5   3   1  \n",
      "6   6   6   7  \n",
      "7   6   7   6  \n",
      "\n",
      "=== Logistic Regression – Tuning Summary ===\n",
      "                   Target        CV (tuning)  \\\n",
      "0  Cervical Lordosis Risk  Stratified 5-Fold   \n",
      "1           Kyphosis Risk  Stratified 5-Fold   \n",
      "2    Lumbar Lordosis Risk  Stratified 4-Fold   \n",
      "3          Scoliosis Risk  Stratified 5-Fold   \n",
      "\n",
      "                                         Best Params  \\\n",
      "0  {'penalty': 'l1', 'C': 1, 'solver': 'liblinear...   \n",
      "1  {'penalty': 'l2', 'C': 1, 'solver': 'liblinear...   \n",
      "2  {'penalty': 'l2', 'C': 10, 'solver': 'liblinea...   \n",
      "3  {'penalty': 'l2', 'C': 10, 'solver': 'liblinea...   \n",
      "\n",
      "   Mean CV (balanced_accuracy)  \n",
      "0                        0.915  \n",
      "1                        0.792  \n",
      "2                        0.533  \n",
      "3                        0.592  \n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Logistic Regression (LR) \n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import statsmodels.stats.proportion as smp\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# -----------------------\n",
    "# 0) Ayarlar\n",
    "# -----------------------\n",
    "FILE_PATH = \"ML_Analysis_V3.xlsx\"   # <-- kendi yolun\n",
    "TARGETS = [\"Cervical Lordosis Risk\",\"Kyphosis Risk\",\"Lumbar Lordosis Risk\",\"Scoliosis Risk\"]\n",
    "RUN_LOSO = False   # hızlı başlamak için False; hazır olunca True yap\n",
    "TUNING_SCORING = \"balanced_accuracy\" # veya \"f1_macro\"\n",
    "\n",
    "# -----------------------\n",
    "# 1) Veri seti\n",
    "# -----------------------\n",
    "df = pd.read_excel(FILE_PATH, sheet_name=\"Sheet1\")\n",
    "feature_cols = [c for c in df.columns if c not in TARGETS]\n",
    "\n",
    "# -----------------------\n",
    "# 2) Yardımcılar\n",
    "# -----------------------\n",
    "def make_adaptive_sampler(y_train):\n",
    "    counts = y_train.value_counts().to_dict()\n",
    "    minority_n = min(counts.get(0, 0), counts.get(1, 0))\n",
    "    if minority_n >= 3:\n",
    "        k = max(1, min(5, minority_n - 1))\n",
    "        return SMOTE(k_neighbors=k, random_state=42)\n",
    "    else:\n",
    "        return RandomOverSampler(random_state=42)\n",
    "\n",
    "def get_stratified_cv(y, desired_splits):\n",
    "    minority_n = y.value_counts().min()\n",
    "    n_splits = max(2, min(desired_splits, int(minority_n))) if int(minority_n) > 1 else 2\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42), n_splits\n",
    "\n",
    "def fit_predict_one_fold_lr(X_train, y_train, X_test, lr_params):\n",
    "    sampler = make_adaptive_sampler(y_train)\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('sampler', sampler),\n",
    "        ('lr', LogisticRegression(**lr_params))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    return pipe.predict(X_test)\n",
    "\n",
    "def global_tune_lr(X, y, desired_splits=5, scoring=\"balanced_accuracy\"):\n",
    "    skf, used_splits = get_stratified_cv(y, desired_splits)\n",
    "    grid = {\n",
    "        \"penalty\": [\"l2\", \"l1\"],\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"solver\": [\"liblinear\"],\n",
    "        \"class_weight\": [\"balanced\"],\n",
    "        \"max_iter\": [2000]\n",
    "    }\n",
    "    keys = list(grid.keys()); vals = [grid[k] for k in keys]\n",
    "    best_score, best_params = -np.inf, None\n",
    "    for combo in product(*vals):\n",
    "        p = dict(zip(keys, combo))\n",
    "        fold_scores = []\n",
    "        for tr, va in skf.split(X, y):\n",
    "            X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "            y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "            sampler = make_adaptive_sampler(y_tr)\n",
    "            pipe = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('sampler', sampler),\n",
    "                ('lr', LogisticRegression(**p))\n",
    "            ])\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "            pred = pipe.predict(X_va)\n",
    "            s = balanced_accuracy_score(y_va, pred) if scoring==\"balanced_accuracy\" else f1_score(y_va, pred, average=\"macro\")\n",
    "            fold_scores.append(s)\n",
    "        m = np.mean(fold_scores)\n",
    "        if m > best_score:\n",
    "            best_score, best_params = m, p\n",
    "    return best_params, best_score, used_splits\n",
    "\n",
    "def evaluate_scheme_lr(X, y, splitter, scheme_name, lr_params):\n",
    "    splits = splitter.split(X, y) if isinstance(splitter, StratifiedKFold) else splitter.split(X)\n",
    "    y_true, y_pred = [], []\n",
    "    for tr, te in splits:\n",
    "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
    "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
    "        pred = fit_predict_one_fold_lr(X_tr, y_tr, X_te, lr_params)\n",
    "        y_true.extend(y_te); y_pred.extend(pred)\n",
    "    rep = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    n = len(y_true); k = int((np.array(y_true) == np.array(y_pred)).sum())\n",
    "    ci_lo, ci_hi = smp.proportion_confint(k, n, alpha=0.05, method='wilson')\n",
    "    return {\n",
    "        \"Scheme\": scheme_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"95% CI Low\": ci_lo, \"95% CI High\": ci_hi,\n",
    "        \"Weighted Precision\": rep[\"weighted avg\"][\"precision\"],\n",
    "        \"Weighted Recall\": rep[\"weighted avg\"][\"recall\"],\n",
    "        \"Weighted F1\": rep[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Support\": int(cm.sum()), \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp)\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# 3) Çalıştır\n",
    "# -----------------------\n",
    "all_rows, tuning_rows = [], []\n",
    "for target in TARGETS:\n",
    "    print(f\"\\n=== LR Tuning & Evaluation for: {target} ===\")\n",
    "    X = df[feature_cols].copy(); y = df[target].copy()\n",
    "\n",
    "    best_params, best_cv, used_splits = global_tune_lr(X, y, desired_splits=5, scoring=TUNING_SCORING)\n",
    "    print(f\"Best params (Stratified {used_splits}-Fold): {best_params} | Mean CV ({TUNING_SCORING}): {round(best_cv,3)}\")\n",
    "    tuning_rows.append({\"Target\": target, \"CV (tuning)\": f\"Stratified {used_splits}-Fold\",\n",
    "                        \"Best Params\": best_params, f\"Mean CV ({TUNING_SCORING})\": round(best_cv,3)})\n",
    "\n",
    "    if RUN_LOSO:\n",
    "        row_loso = evaluate_scheme_lr(X, y, LeaveOneOut(), \"LOSO\", best_params)\n",
    "        all_rows.append({\"Target\": target, **row_loso})\n",
    "\n",
    "    cv5, used5   = get_stratified_cv(y, 5)\n",
    "    cv10, used10 = get_stratified_cv(y, 10)\n",
    "    row_s5  = evaluate_scheme_lr(X, y, cv5,  f\"Stratified {used5}-Fold\",  best_params)\n",
    "    row_s10 = evaluate_scheme_lr(X, y, cv10, f\"Stratified {used10}-Fold\", best_params)\n",
    "    all_rows += [{\"Target\": target, **row_s5}, {\"Target\": target, **row_s10}]\n",
    "\n",
    "summary_lr = pd.DataFrame(all_rows)\n",
    "tuning_summary = pd.DataFrame(tuning_rows)\n",
    "\n",
    "# Kaydetmek istersen:\n",
    "# summary_lr.to_csv(\"LR_Scaled_Balanced_AdaptiveCV_AllTargets.csv\", index=False)\n",
    "# tuning_summary.to_csv(\"LR_Tuning_Summary.csv\", index=False)\n",
    "\n",
    "print(\"\\n=== Logistic Regression – Master Table (adaptive 5/10-Fold [+LOSO if enabled]) ===\")\n",
    "print(summary_lr)\n",
    "print(\"\\n=== Logistic Regression – Tuning Summary ===\")\n",
    "print(tuning_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60585ca-a082-4500-802a-3a83afe477c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
