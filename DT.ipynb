{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824ab8f2-f5d7-45e5-bb3e-e9f07dd0b672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree Tuning & Evaluation for: Cervical Lordosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'random_state': 42} | Mean CV (balanced_accuracy): 0.92\n",
      "\n",
      "=== Decision Tree Tuning & Evaluation for: Kyphosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'random_state': 42} | Mean CV (balanced_accuracy): 0.725\n",
      "\n",
      "=== Decision Tree Tuning & Evaluation for: Lumbar Lordosis Risk ===\n",
      "Best params (Stratified 4-Fold): {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'random_state': 42} | Mean CV (balanced_accuracy): 0.634\n",
      "\n",
      "=== Decision Tree Tuning & Evaluation for: Scoliosis Risk ===\n",
      "Best params (Stratified 5-Fold): {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'random_state': 42} | Mean CV (balanced_accuracy): 0.767\n",
      "\n",
      "=== Decision Tree – Master Table (LOSO + adaptive 5/10-Fold) ===\n",
      "                    Target              Scheme  Accuracy  95% CI Low  \\\n",
      "0   Cervical Lordosis Risk                LOSO  0.900000    0.743789   \n",
      "1   Cervical Lordosis Risk   Stratified 5-Fold  0.866667    0.703187   \n",
      "2   Cervical Lordosis Risk   Stratified 6-Fold  0.900000    0.743789   \n",
      "3            Kyphosis Risk                LOSO  0.766667    0.590717   \n",
      "4            Kyphosis Risk   Stratified 5-Fold  0.700000    0.521242   \n",
      "5            Kyphosis Risk  Stratified 10-Fold  0.733333    0.555520   \n",
      "6     Lumbar Lordosis Risk                LOSO  0.766667    0.590717   \n",
      "7     Lumbar Lordosis Risk   Stratified 4-Fold  0.733333    0.555520   \n",
      "8     Lumbar Lordosis Risk   Stratified 4-Fold  0.733333    0.555520   \n",
      "9           Scoliosis Risk                LOSO  0.700000    0.521242   \n",
      "10          Scoliosis Risk   Stratified 5-Fold  0.766667    0.590717   \n",
      "11          Scoliosis Risk  Stratified 10-Fold  0.766667    0.590717   \n",
      "\n",
      "    95% CI High  Weighted Precision  Weighted Recall  Weighted F1  Support  \\\n",
      "0      0.965400            0.896000         0.900000     0.896475       30   \n",
      "1      0.946903            0.920000         0.866667     0.877273       30   \n",
      "2      0.965400            0.896000         0.900000     0.896475       30   \n",
      "3      0.882076            0.780694         0.766667     0.765888       30   \n",
      "4      0.833353            0.712217         0.700000     0.698999       30   \n",
      "5      0.858173            0.739881         0.733333     0.733333       30   \n",
      "6      0.882076            0.738272         0.766667     0.752201       30   \n",
      "7      0.858173            0.821212         0.733333     0.766667       30   \n",
      "8      0.858173            0.821212         0.733333     0.766667       30   \n",
      "9      0.833353            0.703571         0.700000     0.701010       30   \n",
      "10     0.882076            0.765741         0.766667     0.765333       30   \n",
      "11     0.882076            0.765741         0.766667     0.765333       30   \n",
      "\n",
      "    TN  FP  FN  TP  \n",
      "0   23   1   2   4  \n",
      "1   20   4   0   6  \n",
      "2   23   1   2   4  \n",
      "3   12   2   5  11  \n",
      "4   11   3   6  10  \n",
      "5   11   3   5  11  \n",
      "6   23   3   4   0  \n",
      "7   20   6   2   2  \n",
      "8   20   6   2   2  \n",
      "9   12   5   4   9  \n",
      "10  14   3   4   9  \n",
      "11  14   3   4   9  \n",
      "\n",
      "=== Decision Tree – Tuning Summary ===\n",
      "                   Target        CV (tuning)  \\\n",
      "0  Cervical Lordosis Risk  Stratified 5-Fold   \n",
      "1           Kyphosis Risk  Stratified 5-Fold   \n",
      "2    Lumbar Lordosis Risk  Stratified 4-Fold   \n",
      "3          Scoliosis Risk  Stratified 5-Fold   \n",
      "\n",
      "                                         Best Params  \\\n",
      "0  {'criterion': 'gini', 'max_depth': None, 'min_...   \n",
      "1  {'criterion': 'gini', 'max_depth': 2, 'min_sam...   \n",
      "2  {'criterion': 'gini', 'max_depth': 3, 'min_sam...   \n",
      "3  {'criterion': 'entropy', 'max_depth': 3, 'min_...   \n",
      "\n",
      "   Mean CV (balanced_accuracy)  \n",
      "0                        0.920  \n",
      "1                        0.725  \n",
      "2                        0.634  \n",
      "3                        0.767  \n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Decision Tree (DT)\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import statsmodels.stats.proportion as smp\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# -----------------------\n",
    "# 0) Ayarlar\n",
    "# -----------------------\n",
    "FILE_PATH = \"ML_Analysis_V3.xlsx\"   # <-- kendi yolun\n",
    "TARGETS = [\"Cervical Lordosis Risk\",\"Kyphosis Risk\",\"Lumbar Lordosis Risk\",\"Scoliosis Risk\"]\n",
    "RUN_LOSO = True                     # hızlı istersen False yap\n",
    "TUNING_SCORING = \"balanced_accuracy\"  # alternatif: \"f1_macro\"\n",
    "\n",
    "# -----------------------\n",
    "# 1) Veri seti\n",
    "# -----------------------\n",
    "df = pd.read_excel(FILE_PATH, sheet_name=\"Sheet1\")\n",
    "feature_cols = [c for c in df.columns if c not in TARGETS]\n",
    "\n",
    "# -----------------------\n",
    "# 2) Yardımcılar\n",
    "# -----------------------\n",
    "def make_adaptive_sampler(y_train):\n",
    "    \"\"\"\n",
    "    Minority sayısına göre SMOTE(k) ya da ROS seç.\n",
    "    minority >= 3 -> SMOTE(k = min(5, minority-1))\n",
    "    aksi halde -> ROS\n",
    "    \"\"\"\n",
    "    counts = y_train.value_counts().to_dict()\n",
    "    minority_n = min(counts.get(0, 0), counts.get(1, 0))\n",
    "    if minority_n >= 3:\n",
    "        k = max(1, min(5, minority_n - 1))\n",
    "        return SMOTE(k_neighbors=k, random_state=42)\n",
    "    else:\n",
    "        return RandomOverSampler(random_state=42)\n",
    "\n",
    "def get_stratified_cv(y, desired_splits):\n",
    "    \"\"\"\n",
    "    StratifiedKFold kat sayısını, min sınıf adedini aşmayacak şekilde adaptif seç.\n",
    "    \"\"\"\n",
    "    minority_n = y.value_counts().min()\n",
    "    n_splits = max(2, min(desired_splits, int(minority_n))) if int(minority_n) > 1 else 2\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42), n_splits\n",
    "\n",
    "def fit_predict_one_fold_dt(X_train, y_train, X_test, dt_params):\n",
    "    \"\"\"\n",
    "    Tek fold eğitimi: Sampler -> DecisionTree\n",
    "    (Ağaçlar ölçekten etkilenmediği için scaler kullanmıyoruz.)\n",
    "    \"\"\"\n",
    "    sampler = make_adaptive_sampler(y_train)\n",
    "    pipe = Pipeline([\n",
    "        ('sampler', sampler),\n",
    "        ('dt', DecisionTreeClassifier(**dt_params))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    return pipe.predict(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# 3) Global tuning (hızlı)\n",
    "# -----------------------\n",
    "def global_tune_dt(X, y, desired_splits=5, scoring=\"balanced_accuracy\"):\n",
    "    skf, used_splits = get_stratified_cv(y, desired_splits)\n",
    "\n",
    "    # Param grid (küçük ve etkili; aşırı grid küçük veride aşırı uyum yapar)\n",
    "    grid = {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [None, 2, 3, 4, 5],\n",
    "        \"min_samples_split\": [2, 3, 4, 5],\n",
    "        \"min_samples_leaf\": [1, 2, 3],\n",
    "        \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "        \"ccp_alpha\": [0.0, 0.001, 0.01],\n",
    "        \"class_weight\": [\"balanced\"],      # sabit: dengesizlik için\n",
    "        \"random_state\": [42]\n",
    "    }\n",
    "\n",
    "    keys = list(grid.keys())\n",
    "    vals = [grid[k] for k in keys]\n",
    "    best_score, best_params = -np.inf, None\n",
    "\n",
    "    for combo in product(*vals):\n",
    "        p = dict(zip(keys, combo))\n",
    "        fold_scores = []\n",
    "        for tr, va in skf.split(X, y):\n",
    "            X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "            y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "\n",
    "            sampler = make_adaptive_sampler(y_tr)\n",
    "            pipe = Pipeline([\n",
    "                ('sampler', sampler),\n",
    "                ('dt', DecisionTreeClassifier(**p))\n",
    "            ])\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "            pred = pipe.predict(X_va)\n",
    "            s = balanced_accuracy_score(y_va, pred) if scoring==\"balanced_accuracy\" \\\n",
    "                else f1_score(y_va, pred, average=\"macro\")\n",
    "            fold_scores.append(s)\n",
    "\n",
    "        m = np.mean(fold_scores)\n",
    "        if m > best_score:\n",
    "            best_score, best_params = m, p\n",
    "\n",
    "    return best_params, best_score, used_splits\n",
    "\n",
    "# -----------------------\n",
    "# 4) Değerlendirme\n",
    "# -----------------------\n",
    "def evaluate_scheme_dt(X, y, splitter, scheme_name, dt_params):\n",
    "    splits = splitter.split(X, y) if isinstance(splitter, StratifiedKFold) else splitter.split(X)\n",
    "    y_true, y_pred = [], []\n",
    "    for tr, te in splits:\n",
    "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
    "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
    "        pred = fit_predict_one_fold_dt(X_tr, y_tr, X_te, dt_params)\n",
    "        y_true.extend(y_te); y_pred.extend(pred)\n",
    "\n",
    "    rep = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    n = len(y_true); k = int((np.array(y_true) == np.array(y_pred)).sum())\n",
    "    ci_lo, ci_hi = smp.proportion_confint(k, n, alpha=0.05, method='wilson')\n",
    "\n",
    "    return {\n",
    "        \"Scheme\": scheme_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"95% CI Low\": ci_lo, \"95% CI High\": ci_hi,\n",
    "        \"Weighted Precision\": rep[\"weighted avg\"][\"precision\"],\n",
    "        \"Weighted Recall\": rep[\"weighted avg\"][\"recall\"],\n",
    "        \"Weighted F1\": rep[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Support\": int(cm.sum()), \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp)\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# 5) Çalıştır\n",
    "# -----------------------\n",
    "all_rows, tuning_rows = [], []\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\n=== Decision Tree Tuning & Evaluation for: {target} ===\")\n",
    "    X = df[feature_cols].copy(); y = df[target].copy()\n",
    "\n",
    "    best_params, best_cv, used_splits = global_tune_dt(X, y, desired_splits=5, scoring=TUNING_SCORING)\n",
    "    print(f\"Best params (Stratified {used_splits}-Fold): {best_params} | Mean CV ({TUNING_SCORING}): {round(best_cv,3)}\")\n",
    "    tuning_rows.append({\"Target\": target, \"CV (tuning)\": f\"Stratified {used_splits}-Fold\",\n",
    "                        \"Best Params\": best_params, f\"Mean CV ({TUNING_SCORING})\": round(best_cv,3)})\n",
    "\n",
    "    if RUN_LOSO:\n",
    "        row_loso = evaluate_scheme_dt(X, y, LeaveOneOut(), \"LOSO\", best_params)\n",
    "        all_rows.append({\"Target\": target, **row_loso})\n",
    "\n",
    "    cv5, used5   = get_stratified_cv(y, 5)\n",
    "    cv10, used10 = get_stratified_cv(y, 10)\n",
    "\n",
    "    row_s5  = evaluate_scheme_dt(X, y, cv5,  f\"Stratified {used5}-Fold\",  best_params)\n",
    "    row_s10 = evaluate_scheme_dt(X, y, cv10, f\"Stratified {used10}-Fold\", best_params)\n",
    "    all_rows += [{\"Target\": target, **row_s5}, {\"Target\": target, **row_s10}]\n",
    "\n",
    "summary_dt = pd.DataFrame(all_rows)\n",
    "tuning_summary = pd.DataFrame(tuning_rows)\n",
    "\n",
    "print(\"\\n=== Decision Tree – Master Table (LOSO + adaptive 5/10-Fold) ===\")\n",
    "print(summary_dt)\n",
    "print(\"\\n=== Decision Tree – Tuning Summary ===\")\n",
    "print(tuning_summary)\n",
    "\n",
    "# İstersen CSV:\n",
    "# summary_dt.to_csv(\"DT_Balanced_AdaptiveOversampling_AdaptiveCV_AllTargets.csv\", index=False)\n",
    "# tuning_summary.to_csv(\"DT_Tuning_Summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ae32f-9fc7-46e7-81b1-4874342b6618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
